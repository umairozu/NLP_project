{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b56f2-11bc-4546-b8c1-24375a4d7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U accelerate\n",
    "!pip install --upgrade accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657afb57-2bb9-4ec3-8f8f-5716d88cbc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers: 4.40.1\n",
      "Accelerate: 0.27.2\n"
     ]
    }
   ],
   "source": [
    "import transformers, accelerate\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Accelerate:\", accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c709ca-33f8-4ab3-a49a-7b70baf9336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module accelerate.accelerator:\n",
      "\n",
      "__init__(self, device_placement: 'bool' = True, split_batches: 'bool' = False, mixed_precision: 'PrecisionType | str | None' = None, gradient_accumulation_steps: 'int' = 1, cpu: 'bool' = False, deepspeed_plugin: 'DeepSpeedPlugin | None' = None, fsdp_plugin: 'FullyShardedDataParallelPlugin | None' = None, megatron_lm_plugin: 'MegatronLMPlugin | None' = None, rng_types: 'list[str | RNGType] | None' = None, log_with: 'str | LoggerType | GeneralTracker | list[str | LoggerType | GeneralTracker] | None' = None, project_dir: 'str | os.PathLike | None' = None, project_config: 'ProjectConfiguration | None' = None, gradient_accumulation_plugin: 'GradientAccumulationPlugin | None' = None, dispatch_batches: 'bool | None' = None, even_batches: 'bool' = True, use_seedable_sampler: 'bool' = False, step_scheduler_with_optimizer: 'bool' = True, kwargs_handlers: 'list[KwargsHandler] | None' = None, dynamo_backend: 'DynamoBackend | str | None' = None)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments)\n",
    "from accelerate import Accelerator\n",
    "help(Accelerator.__init__)\n",
    "\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0291a4c8-fa58-4c6b-9519-0be91484f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"urdu_annotation.xlsx\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18b0a82-3da8-44c6-869a-28e202f61ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"Sentences\", \"Emotion\"], inplace=True)\n",
    "df = df[df[\"Emotion\"].str.lower() != \"discard\"] \n",
    "df[\"Emotion\"] = df[\"Emotion\"].str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33568bb3-f4e7-4d07-b643-5a126a3a03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"EmotionLabel\"] = label_encoder.fit_transform(df[\"Emotion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d7c286-8422-4d2e-b08d-5080ceb18997",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from emotion_dictionary import emotion_trigger_dict\n",
    "\n",
    "    def has_trigger_word(row):\n",
    "        emotion = row[\"Emotion\"]\n",
    "        sentence = row[\"Sentences\"]\n",
    "        if emotion in emotion_trigger_dict:\n",
    "            return int(any(word in sentence for word in emotion_trigger_dict[emotion]))\n",
    "        return 0\n",
    "\n",
    "    df[\"Has_Trigger\"] = df.apply(has_trigger_word, axis=1)\n",
    "except:\n",
    "    print(\"Trigger word dictionary not found or not used.\")\n",
    "    df[\"Has_Trigger\"] = 0  # fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e676f3cf-d3af-4276-b8f6-3be9775ff341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairahmad/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=df[\"EmotionLabel\"].nunique()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d58dff-b978-4be2-bc41-0ab34c25899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b8e5ab754a45049dd2cd6d80e15463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/932 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df[[\"Sentences\", \"EmotionLabel\", \"Has_Trigger\"]])\n",
    "\n",
    "def tokenize(batch):\n",
    "    encoding = tokenizer(\n",
    "        batch[\"Sentences\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    encoding[\"labels\"] = batch[\"EmotionLabel\"]\n",
    "    return encoding\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e02df3-84e4-45f4-a88a-ff606fd59dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./urdu-emotion-results\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30a8d32-75ca-489c-9625-63fa2d2478a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e8daf4-cc0a-4772-b93f-96a9a11af2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38872237-39f5-4042-98c7-b8223b3319df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairahmad/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [468/468 1:16:22, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.749200</td>\n",
       "      <td>1.733969</td>\n",
       "      <td>0.247854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.787400</td>\n",
       "      <td>1.733346</td>\n",
       "      <td>0.254292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.721900</td>\n",
       "      <td>1.737916</td>\n",
       "      <td>0.247854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.734000</td>\n",
       "      <td>1.731156</td>\n",
       "      <td>0.247854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairahmad/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/umairahmad/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/umairahmad/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Saving model...\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training completed.\")\n",
    "\n",
    "print(\"Saving model...\")\n",
    "trainer.save_model(\"urdu-emotion-model\")\n",
    "tokenizer.save_pretrained(\"urdu-emotion-model\")\n",
    "print(\"Model saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a772671a-f37c-4fcf-aed3-df5792cfad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairahmad/myenv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.40      0.03      0.05       226\n",
      "        fear       0.00      0.00      0.00       125\n",
      "         joy       0.00      0.00      0.00       106\n",
      "        love       0.00      0.00      0.00       150\n",
      "     neutral       0.25      1.00      0.40       231\n",
      "         sad       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           0.25       932\n",
      "   macro avg       0.11      0.17      0.08       932\n",
      "weighted avg       0.16      0.25      0.11       932\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairahmad/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/umairahmad/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/umairahmad/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true_labels = df[\"EmotionLabel\"]\n",
    "\n",
    "pred_output = trainer.predict(tokenized_dataset)\n",
    "pred_labels = pred_output.predictions.argmax(axis=-1)\n",
    "\n",
    "print(classification_report(true_labels, pred_labels, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b0daed-edbc-47cd-b0df-5c90d6d57d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"urdu-emotion-model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"urdu-emotion-model\")\n",
    "\n",
    "def predict_emotion(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "\n",
    "predict_emotion(\"مجھے بہت خوشی محسوس ہو رہی ہے۔\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc6911-4d76-4da6-b487-7d97a151952d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
